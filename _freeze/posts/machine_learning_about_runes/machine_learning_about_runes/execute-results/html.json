{
  "hash": "14e089c0e910b75401a29313ef7afde7",
  "result": {
    "markdown": "---\ntitle: \"(Machine) Learning about Runes\"\ndate: \"2022-06-27\"\ndescription: \"Alphabetic algorithm alchemy.\"\nimage: \"machine_learning_about_runes.jpg\"\n---\n\n\n\n\n## Introduction\n\nToday we'll learn about an ancient Germanic writing system, clean up some messy data, engineer a couple of simple features, and see if we can find a way to predict the age of some historical artifacts without having to pay for a fancy-schmancy archaeology degree. Along the way, we'll get a little overview of the `tidyverse` and `tidymodels` approaches to data analysis and modeling in R.\n\n### A Very Brief Primer on Runes\n\nA rune is a letter from any of a handful of closely-related alphabets used by Germanic peoples primarily from around the 3rd to the 13th centuries CE. Like the Latin alphabet used to write the Germanic languages today, they derive from an ancient form of the Greek alphabet.[^1] These alphabets are sometimes called \"futhark\" (or \"futhorc\", \"fuþąrk\", etc.) after first few letters in their canonical order.[^2]\n\n[^1]: Possibly via one of the alpine Old Italic alphabets such as Venetic.\n\n[^2]: Curiously, the first three letters of these alphabets spell out a vulgar word for a woman's genitals in Old Norse.\n\nThe main runic alphabets are[^3]:\n\n[^3]: The abecedaria, or \"rune rows\", in this table are much simplified. In reality, there were many variations of each. The medieval runes in particular were augmented by diacritical dots in order to disambiguate sounds represented by the same rune in the younger futhark.\n\n| Name                  | Main Language(s)            | Era (c. CE) | Letters                                                 |\n|:----------------------|:----------------------------|:------------|:--------------------------------------------------------|\n| Elder Futhark         | Proto-Germanic, Proto-Norse | 1st--8th    | ᚠ ᚢ ᚦ ᚨ ᚱ ᚲ ᚷ ᚹ ᚺ ᚾ ᛁ ᛃ ᛈ ᛇ ᛉ ᛊ ᛏ ᛒ ᛖ ᛗ ᛚ               |\n| Anglo-Frisian Futhorc | Old Frisian, Old English    | 5th--11th   | ᚠ ᚢ ᚦ ᚩ ᚱ ᚳ ᚷ ᚹ ᚻ ᚾ ᛁ ᛡ ᛇ ᛈ ᛉ ᛋ ᛏ ᛒ ᛖ ᛗ ᛚ ᛝ ᛟ ᛞ ᚪ ᚫ ᛠ ᚣ |\n| Younger Futhark       | Old Norse                   | 8th--12th   | ᚠ ᚢ ᚦ ᚬ ᚱ ᚴ ᚼ ᚾ ᛁ ᛅ ᛦ ᛋ ᛏ ᛒ ᛘ ᛚ                         |\n| Medieval Runes        | Old Icelandic, Old Swedish  | 12th--17th  | ᚠ ᚢ ᚦ ᚮ ᚱ ᚴ ᚼ ᚿ ᛁ ᛆ ᛌ ᛐ ᛒ ᛘ ᛚ ᛦ                         |\n\nMagical incantations were sometimes written in runes, but despite what such august institutions as the gift shop of the National Museum of Iceland would have you believe, there's no evidence that each runic letter had a specific symbolic meaning.[^4] Neither is there much evidence that they were used in divination. These alphabets were used mainly for mundane purposes such as inscribing an object with its owner or creator's name, and for memorializing the dead on gravestones. Nevertheless, in recent times these alphabets have become an element in various kinds of New Age mysticism, neo-pagan religions, and unsavoury political movements.\n\n[^4]: The runes have mnemonic names, and occasionally a rune could stand in for its name, but even this is rare.\n\n### RuneS-DB\n\nRuneS-DB is a database of artifacts bearing runic writing compiled from a variety of sources as part of RuneS, an overarching project to study these writing systems. It's available from the RuneS project's website.\n\n> The rights to the data are held by the Göttingen Academy of Sciences and Humanities and are subject to the CC-BY- SA law. The RuneS research units Göttingen, Eichstätt-München and Kiel were involved in the generation of the data. RuneS-DB contains data from the Kiel Runenprojekt, the Danish database runer.ku.dk and the Samnordisk runtextdatabas/Rundata accessible under the Open Database License (ODbL). Please also note the additional information on other origin of the data provided under the label sources.\n\nRuneS provides a tool on their website to query the database, but it's pretty clunky. Instead, we'll use R to see if we can learn anything interesting.\n\n### Tools\n\nWe'll use the `tidyverse` collection of packages for manipulating and visualizing our data and the `tidymodels` packages to quickly define, train, and compare a few machine learning models. These packages \"share an underlying design philosophy, grammar, and data structures\" rooted in the \"tidy data\" principles originally espoused by [Hadley Wickham](https://twitter.com/hadleywickham).\n\nThis document was lovingly hand-crafted in artisanal, farm-to-table, GMO-free [Quarto](https://quarto.org/).\n\n## Reading and Cleaning the Data\n\n### Reading the File\n\nThe file we obtain from the RuneS website is tab-separated, contains three lines of preamble, and uses a hyphen to indicate missing data. Providing this information to `readr`'s `read_delim` will produce a tibble (i.e., a fancy data frame, which is in turn a fancy matrix) that we can begin to manipulate.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# read the file\nread_delim(file = \"runes_data.csv\",\n           delim = \";\",\n           skip = 3,\n           na = \"-\",\n           show_col_types = FALSE) ->\n  # save to a dataframe\n  runes_data\n```\n:::\n\n\n### The Vimose Comb\n\nOne artifact we'd expect to find in RuneS-DB is the [Vimose comb](https://en.wikipedia.org/wiki/Vimose_inscriptions), which bears what's considered to be the oldest known datable[^5] runic inscription. `dplyr`'s `filter` function and `stringr`'s `str_detect` let us filter the data to show only rows where value in the column of inscription names matches \"Vimose comb\".[^6]\n\n[^5]: Insert joke about \"datable\" here.\n\n[^6]: Just checking for `rs_short_inscr_name == \"Vimose comb\"` would fail because the values in that column have extra whitespace characters.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_data |>\n  filter(str_detect(rs_short_inscr_name, pattern = \"Vimose comb\")) |>\n  kbl() |>\n  scroll_box(width = \"51.75%\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div style=\"border: 1px solid #ddd; padding: 5px; overflow-x: scroll; width:51.75%; \"><table>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> Findno </th>\n   <th style=\"text-align:left;\"> rs_short_inscr_name </th>\n   <th style=\"text-align:left;\"> rs_fundort </th>\n   <th style=\"text-align:left;\"> rs_short_storage </th>\n   <th style=\"text-align:left;\"> rs_extdat </th>\n   <th style=\"text-align:left;\"> rs_short_dat_art </th>\n   <th style=\"text-align:left;\"> rs_short_context </th>\n   <th style=\"text-align:left;\"> rs_objklasse </th>\n   <th style=\"text-align:left;\"> rs_objtyp </th>\n   <th style=\"text-align:left;\"> rs_short_obj_complete </th>\n   <th style=\"text-align:left;\"> rs_short_matklasse </th>\n   <th style=\"text-align:left;\"> rs_mat </th>\n   <th style=\"text-align:left;\"> rs_short_obj_state </th>\n   <th style=\"text-align:left;\"> rs_runenreihe </th>\n   <th style=\"text-align:left;\"> rs_short_museum </th>\n   <th style=\"text-align:left;\"> rs_short_ins_complete </th>\n   <th style=\"text-align:left;\"> rs_translat </th>\n   <th style=\"text-align:left;\"> rs_translit </th>\n   <th style=\"text-align:left;\"> rs_short_ins_state </th>\n   <th style=\"text-align:left;\"> rs_short_markings </th>\n   <th style=\"text-align:left;\"> rs_short_transkript </th>\n   <th style=\"text-align:left;\"> rs_namen </th>\n   <th style=\"text-align:left;\"> rs_fundjahr </th>\n   <th style=\"text-align:left;\"> rs_short_gemeinde </th>\n   <th style=\"text-align:left;\"> rs_short_bezirk </th>\n   <th style=\"text-align:left;\"> rs_short_landschaft </th>\n   <th style=\"text-align:left;\"> rs_short_land </th>\n   <th style=\"text-align:left;\"> rs_short_invnr </th>\n   <th style=\"text-align:left;\"> rs_short_kategorie </th>\n   <th style=\"text-align:left;\"> rs_short_sigils </th>\n   <th style=\"text-align:left;\"> rs_traeger </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 20 </td>\n   <td style=\"text-align:left;\"> Vimose comb </td>\n   <td style=\"text-align:left;\"> Vimose </td>\n   <td style=\"text-align:left;\"> Museum </td>\n   <td style=\"text-align:left;\"> 140-160 </td>\n   <td style=\"text-align:left;\"> arch. </td>\n   <td style=\"text-align:left;\"> deposit find </td>\n   <td style=\"text-align:left;\"> tool/implement </td>\n   <td style=\"text-align:left;\"> personal hygiene </td>\n   <td style=\"text-align:left;\"> yes </td>\n   <td style=\"text-align:left;\"> bone/horn </td>\n   <td style=\"text-align:left;\"> antler </td>\n   <td style=\"text-align:left;\"> good </td>\n   <td style=\"text-align:left;\"> older fuþark </td>\n   <td style=\"text-align:left;\"> Nationalmuseet </td>\n   <td style=\"text-align:left;\"> yes </td>\n   <td style=\"text-align:left;\"> Harja. </td>\n   <td style=\"text-align:left;\"> harja | </td>\n   <td style=\"text-align:left;\"> good </td>\n   <td style=\"text-align:left;\"> nein </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> Vimose-kam </td>\n   <td style=\"text-align:left;\"> 1865 </td>\n   <td style=\"text-align:left;\"> Allese Sogn </td>\n   <td style=\"text-align:left;\"> Odense Amt </td>\n   <td style=\"text-align:left;\"> Fyn </td>\n   <td style=\"text-align:left;\"> DK </td>\n   <td style=\"text-align:left;\"> 22657 </td>\n   <td style=\"text-align:left;\"> run. </td>\n   <td style=\"text-align:left;\"> Fyn 19 </td>\n   <td style=\"text-align:left;\"> comb </td>\n  </tr>\n</tbody>\n</table></div>\n\n`````\n:::\n:::\n\n\nSo we can see that this object was found in Vimose, currently resides in a museum, has been dated to 140-160 CE, is a personal hygiene tool made of antler, says \"harja\" (ᚺᚨᚱᛃᚨ), etc.\n\n### Diagnosing\n\nOne way to quantify the messiness of a data set is to calculate the count and proportion of missing and unique values in each column. `dlookr`'s `diagnose` does this.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_data |> \n  diagnose() |>\n  kbl() |>\n  scroll_box(width = \"51.75%\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div style=\"border: 1px solid #ddd; padding: 5px; overflow-x: scroll; width:51.75%; \"><table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> variables </th>\n   <th style=\"text-align:left;\"> types </th>\n   <th style=\"text-align:right;\"> missing_count </th>\n   <th style=\"text-align:right;\"> missing_percent </th>\n   <th style=\"text-align:right;\"> unique_count </th>\n   <th style=\"text-align:right;\"> unique_rate </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Findno </td>\n   <td style=\"text-align:left;\"> numeric </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.0000000 </td>\n   <td style=\"text-align:right;\"> 8281 </td>\n   <td style=\"text-align:right;\"> 1.0000000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_inscr_name </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 7 </td>\n   <td style=\"text-align:right;\"> 0.0845309 </td>\n   <td style=\"text-align:right;\"> 5457 </td>\n   <td style=\"text-align:right;\"> 0.6589784 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_fundort </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 34 </td>\n   <td style=\"text-align:right;\"> 0.4105784 </td>\n   <td style=\"text-align:right;\"> 3156 </td>\n   <td style=\"text-align:right;\"> 0.3811134 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_storage </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0.0000000 </td>\n   <td style=\"text-align:right;\"> 1723 </td>\n   <td style=\"text-align:right;\"> 0.2080667 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_extdat </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:right;\"> 0.0724550 </td>\n   <td style=\"text-align:right;\"> 573 </td>\n   <td style=\"text-align:right;\"> 0.0691945 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_dat_art </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 1988 </td>\n   <td style=\"text-align:right;\"> 24.0067625 </td>\n   <td style=\"text-align:right;\"> 19 </td>\n   <td style=\"text-align:right;\"> 0.0022944 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_context </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 5240 </td>\n   <td style=\"text-align:right;\"> 63.2773820 </td>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:right;\"> 0.0025359 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_objklasse </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 33 </td>\n   <td style=\"text-align:right;\"> 0.3985026 </td>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:right;\"> 0.0015699 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_objtyp </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 1452 </td>\n   <td style=\"text-align:right;\"> 17.5341142 </td>\n   <td style=\"text-align:right;\"> 45 </td>\n   <td style=\"text-align:right;\"> 0.0054341 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_obj_complete </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 1873 </td>\n   <td style=\"text-align:right;\"> 22.6180413 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 0.0004830 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_matklasse </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 43 </td>\n   <td style=\"text-align:right;\"> 0.5192610 </td>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:right;\"> 0.0013283 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_mat </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 3550 </td>\n   <td style=\"text-align:right;\"> 42.8692187 </td>\n   <td style=\"text-align:right;\"> 119 </td>\n   <td style=\"text-align:right;\"> 0.0143702 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_obj_state </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 1970 </td>\n   <td style=\"text-align:right;\"> 23.7893974 </td>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:right;\"> 0.0007246 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_runenreihe </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 463 </td>\n   <td style=\"text-align:right;\"> 5.5911122 </td>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:right;\"> 0.0014491 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_museum </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 4382 </td>\n   <td style=\"text-align:right;\"> 52.9163145 </td>\n   <td style=\"text-align:right;\"> 291 </td>\n   <td style=\"text-align:right;\"> 0.0351407 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_ins_complete </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 1259 </td>\n   <td style=\"text-align:right;\"> 15.2034778 </td>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 0.0004830 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_translat </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 698 </td>\n   <td style=\"text-align:right;\"> 8.4289337 </td>\n   <td style=\"text-align:right;\"> 5592 </td>\n   <td style=\"text-align:right;\"> 0.6752808 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_translit </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 91 </td>\n   <td style=\"text-align:right;\"> 1.0989011 </td>\n   <td style=\"text-align:right;\"> 7482 </td>\n   <td style=\"text-align:right;\"> 0.9035141 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_ins_state </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 1371 </td>\n   <td style=\"text-align:right;\"> 16.5559715 </td>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:right;\"> 0.0007246 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_markings </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 2676 </td>\n   <td style=\"text-align:right;\"> 32.3149378 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 0.0003623 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_transkript </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 1090 </td>\n   <td style=\"text-align:right;\"> 13.1626615 </td>\n   <td style=\"text-align:right;\"> 5536 </td>\n   <td style=\"text-align:right;\"> 0.6685183 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_namen </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 5662 </td>\n   <td style=\"text-align:right;\"> 68.3733849 </td>\n   <td style=\"text-align:right;\"> 1554 </td>\n   <td style=\"text-align:right;\"> 0.1876585 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_fundjahr </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 4895 </td>\n   <td style=\"text-align:right;\"> 59.1112185 </td>\n   <td style=\"text-align:right;\"> 700 </td>\n   <td style=\"text-align:right;\"> 0.0845309 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_gemeinde </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 1435 </td>\n   <td style=\"text-align:right;\"> 17.3288250 </td>\n   <td style=\"text-align:right;\"> 1682 </td>\n   <td style=\"text-align:right;\"> 0.2031156 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_bezirk </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 3287 </td>\n   <td style=\"text-align:right;\"> 39.6932738 </td>\n   <td style=\"text-align:right;\"> 406 </td>\n   <td style=\"text-align:right;\"> 0.0490279 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_landschaft </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 1384 </td>\n   <td style=\"text-align:right;\"> 16.7129574 </td>\n   <td style=\"text-align:right;\"> 124 </td>\n   <td style=\"text-align:right;\"> 0.0149740 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_land </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 48 </td>\n   <td style=\"text-align:right;\"> 0.5796401 </td>\n   <td style=\"text-align:right;\"> 28 </td>\n   <td style=\"text-align:right;\"> 0.0033812 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_invnr </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 4709 </td>\n   <td style=\"text-align:right;\"> 56.8651129 </td>\n   <td style=\"text-align:right;\"> 2524 </td>\n   <td style=\"text-align:right;\"> 0.3047941 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_kategorie </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 1227 </td>\n   <td style=\"text-align:right;\"> 14.8170511 </td>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:right;\"> 0.0018114 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_short_sigils </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 125 </td>\n   <td style=\"text-align:right;\"> 1.5094795 </td>\n   <td style=\"text-align:right;\"> 8129 </td>\n   <td style=\"text-align:right;\"> 0.9816447 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> rs_traeger </td>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:right;\"> 8 </td>\n   <td style=\"text-align:right;\"> 0.0966067 </td>\n   <td style=\"text-align:right;\"> 416 </td>\n   <td style=\"text-align:right;\"> 0.0502355 </td>\n  </tr>\n</tbody>\n</table></div>\n\n`````\n:::\n:::\n\n\nUnfortunately, RuneS-DB is a bit of a mess. Because it's amalgamated from many sources, information is coded inconsistently. A mix of languages are used, including in the column names. Getting this data set clean enough to start visualizing it is easy enough using `dplyr` functions like `rename()`, `separate()`, and `mutate()`.\n\nThe first step is to make the column names more informative and get rid of the weird \"rs\\_\" and \"rs_short\\_\" prefixes.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_data |>\n  # rename the columns\n  rename(\n    find_number          = Findno,\n    inscription_name     = rs_short_inscr_name,\n    location             = rs_short_storage,\n    date                 = rs_extdat,\n    dating_method        = rs_short_dat_art,\n    context              = rs_short_context,\n    findspot             = rs_fundort,\n    object_class         = rs_objklasse,\n    object_type          = rs_objtyp,\n    object_complete      = rs_short_obj_complete,\n    material_class       = rs_short_matklasse,\n    material             = rs_mat,\n    object_state         = rs_short_obj_state,\n    writing_system       = rs_runenreihe,\n    museum               = rs_short_museum,\n    inscription_complete = rs_short_ins_complete,\n    translation          = rs_translat,\n    transliteration      = rs_translit,\n    inscription_state    = rs_short_ins_state,\n    markings             = rs_short_markings,\n    transcription        = rs_short_transkript,\n    names                = rs_namen,\n    find_year            = rs_fundjahr,\n    community            = rs_short_gemeinde,\n    district             = rs_short_bezirk,\n    region               = rs_short_landschaft,\n    country              = rs_short_land,\n    inventory_number     = rs_short_invnr,\n    category             = rs_short_kategorie,\n    shelf_marks          = rs_short_sigils,\n    carrier              = rs_traeger\n  ) ->\n  # update the dataframe\n  runes_data\n```\n:::\n\n\nNext we'll separate the `location` column into two columns, one with the general category and the other with the rest of the information. We'll also create separate columns for the lower and upper bounds of each date, then convert this into a midpoint and a range.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_data |>\n  # separate location category and detail\n  separate(\n    location,\n    into = c(\"location_class\", \"location_detail\"),\n    sep = \":\",\n    extra = \"merge\") |>\n  # separate the date column into lower and upper bounds\n  separate(date, into = c(\"date_lower\", \"date_upper\")) |>\n  mutate(\n    # set dates to NA for undated objects\n    across(starts_with(\"date\"), ~ na_if(., \"0\")),\n    # treat the dates as numbers\n    across(starts_with(\"date\"), ~ as.numeric(.)),\n    # get the middle of each date range\n    date = (date_lower + date_upper) / 2,\n    # get the range of each date\n    date_range = date_upper - date_lower) |>\n  # discard the date bounds\n  select(-c(date_upper, date_lower)) ->\n  # update the dataframe again\n  runes_data\n```\n:::\n\n\nNext let's convert RuneS-DB's somewhat idiosyncratic country codes into human-readable names. While we're at it, we'll collapse the rarest ones into a \"Rest of World\" category.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_data |>\n  mutate(\n    country = recode(\n      country,\n      \"S\"  = \"Sweden\",\n      \"N\"  = \"Norway\",\n      \"DK\" = \"Denmark\",\n      \"IS\" = \"Iceland\",\n      \"GB\" = \"Great Britain\",\n      \"D\"  = \"Germany\",\n      \"KN\" = \"Greenland\",\n      .default = \"Rest of World\")) ->\n  runes_data\n```\n:::\n\n\nFinally some miscellaneous re-encoding.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_data |>\n  mutate(\n    # treat the ID numbers as strings\n    find_number = as.character(find_number),\n    # eliminate excess whitespace\n    across(where(is.character), str_squish),\n    # translate the markings column into English\n    markings = recode(markings, \"ja\" = \"yes\", \"nein\" = \"no\"),\n    # replace cross symbol\n    across(where(is.character), ~ recode(., \"†\" = \"lost/destroyed\")),\n    # replace \"rune stick/rúnakefli\", shorten \"weapon/weapon accessories\"\n    object_class = recode(\n      iconv(object_class, to = 'ASCII//TRANSLIT'),\n      \"rune stick/runakefli\" = \"rune stick\",\n      \"weapon/weapon accessories\" = \"weapon/accessory\"),\n    # make \"Museum\" lowercase for consistency\n    location_class = recode(location_class, \"Museum\" = \"museum\"),\n    # combine parchment and paper into a single material class\n    material_class = recode(\n      material_class,\n      \"parchment; paper\" = \"parchment/paper\",\n      \"parchment\" = \"parchment/paper\",\n      \"paper\" = \"parchment/paper\"),\n    # give the writing systems friendlier names, combine medieval and post-Reformation runes as \"manuscript runes\"\n    writing_system = recode(\n      iconv(writing_system, to = 'ASCII//TRANSLIT'),\n      \"older fu?ark\" = \"elder futhark\",\n      \"younger fu?ark\" = \"younger futhark\",\n      \"fu?orc\" = \"anglo-frisian futhorc\",\n      \"post-Reformation runes\" = \"manuscript runes\",\n      \"medieval runes\" = \"manuscript runes\",\n      .default = \"mixed/unknown\")) ->\n  runes_data\n```\n:::\n\n\nThere's more cleaning we could do, but this is enough for now.\n\n## Exploratory Data Analysis\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-hide .cell-code}\nrunes_data |>\n  drop_na(object_class, material_class) |>\n  group_by(object_class, material_class) |>\n  summarise(count = n()) |>\n  ggplot(aes(x = object_class, y = material_class, size = count)) +\n  geom_point(shape = 21, fill = \"#595959\") +\n  coord_flip() +\n  scale_size(range = c(0, 10)) +\n  guides(size = \"none\") +\n  labs(\n    title = \"Runic Artifacts by Object and Material Class\",\n    x = \"Object Class\",\n    y = \"Material Class\")\n```\n\n::: {.cell-output-display}\n![](machine_learning_about_runes_files/figure-html/object class vs material class-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nNearly half of the artifacts in RuneS-DB are stones[^7], which it turns out are always made of stone! Likewise, coins and bracteates[^8] are always made of metal, and rune sticks are always made of wood. Tools, edifices, \"inventory\" (mostly furniture), and \"other objects\" all seem to come in a variety of materials.\n\n[^7]: [Good old rock, nothin' beats that!](https://frinkiac.com/meme/S04E19/338003.jpg?b64lines=R09PRCBPTEQgUk9DSy4gIApOT1RISU5HIEJFQVRTIFRIQVQu)\n\n[^8]: What's a bracteate, you ask? Why, it's \"is\"a flat, thin, single-sided gold medal worn as jewelry\".\n\nWhere is this stuff typically found?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-hide .cell-code}\nrunes_data |>\n  # discard artifacts missing country information\n  drop_na(country) |>\n  ggplot(aes(fct_infreq(country))) +\n  geom_bar() +\n  geom_hline(yintercept = seq(0, 4000, 1000), color = \"white\") +\n  coord_flip() +\n  labs(\n    title = \"Runic Objects by Country\",\n    x = \"Country of Discovery\",\n    y = \"Number of Objects\")\n```\n\n::: {.cell-output-display}\n![](machine_learning_about_runes_files/figure-html/location graphic-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nRight. Scandinavia, mostly.\n\nOne last exploratory graphic. How old is this stuff?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .fold-hide .cell-code}\nrunes_data |>\n  # discard undated objects\n  drop_na(date) |>\n  ggplot(aes(date)) +\n  # bin into centuries\n  geom_histogram(\n    fill = \"#595959\", \n    color = \"white\", \n    breaks = seq(1, 2022, by=100)) +\n  geom_hline(yintercept = seq(0, 3000, 1000), color = \"white\") +\n  scale_x_continuous(breaks = seq(0, 2000, by = 100)) +\n  labs(\n    title = \"Number of Runic Objects by Century\",\n    x = \"Year of Manufacture\",\n    y = \"Number of Objects\")\n```\n\n::: {.cell-output-display}\n![](machine_learning_about_runes_files/figure-html/dates graphic-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThis histogram has a huge spike at the 10th century. Upon cursory investigation, this seems to be because the data set contains many rune stones with dated to the rather wide range of \"725-1100\", i.e. the Viking Age. Obviously this data set is not random sample of all runic objects ever produced; some things are more likely to survive and be cataloged than others. The smaller spike at the 13th century seems to be more organic.\n\n## Feature Engineering\n\nSuppose you're lost in the woods in northwestern Europe[^9] and stumble upon some runes. Is there some rule you can use to estimate when they were carved (or written)?\n\n[^9]: What do you do if you're lost in the woods in Iceland? Stand up.\n\nFirst, we need to consider what features of the object you'd be able to determine. I think these are all reasonable:\n\n-   object class (stone, coin, etc.)\n-   material class (stone, metal, wood, etc.)\n-   country\n-   writing system (elder futhark, anglo-frisian futhorc, etc.)\n-   length of the inscription\n-   whether the inscription contains an abecedarium; something like \"fuþarkgw...\" or \"abcdefgh...\"\n-   whether the inscription seems to contain any of a few common words or morphemes\n\nThe first four of these features are already present in our data frame. We'll have to \"engineer\" the others.\n\nUnfortunately, the transliterations in RuneS-DB are very inconsistently encoded, but we can still get an approximate length of each inscription by converting the transliteration to ASCII[^10] and counting the number of resulting alphanumeric characters[^11]. It's too bad the database doesn't simply use the runic characters included in Unicode, but perhaps that wouldn't be sufficient to encode parts of the inscriptions which are unclear, damaged, combined into ligatures (so-called \"bind runes\"), etc.\n\n[^10]: Note that different operating systems have different ideas about how to convert other encodings into ASCII.\n\n[^11]: Plus question marks, to account for some of the non-ASCII letters.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_data |>\n  mutate(\n    inscription_length =\n      transliteration |>\n      # convert to ASCII\n      iconv(to = \"ASCII//TRANSLIT\") |>\n      # count alphanumeric characters\n      str_count(\"[[:lower:]\\\\?]\")) ->\n  runes_data\n```\n:::\n\n\nWe can identify abecedaria by slightly re-encoding the \"category\" column.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_data |>\n  mutate(\n    abecedarium = case_when(\n      str_detect(category, \"alphabet\") ~ \"abc\",\n      str_detect(category, \"row\") ~ \"futh\",\n      TRUE ~ \"no\")) ->\n  runes_data\n```\n:::\n\n\nAnother feature we can derive from the inscription is what kind of spacing is used between words.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_data |>\n  mutate(\n    spaces = case_when(\n      str_detect(transliteration, \" [÷\\\\*\\\\+] \") ~ \"crosses/stars\",\n      str_detect(transliteration, \" × \") ~ \"crosses/stars\",\n      str_detect(transliteration, \" [ˈ\\\\.] \") ~ \"single dots\",\n      str_detect(transliteration, \" : \") ~ \"double dots\",\n      TRUE ~ \"none/other\")) ->\n  runes_data\n```\n:::\n\n\nFinally let's encode the presence or absence of a few of the most common words/morphemes.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_data |>\n  mutate(\n    sin_sun_syn = str_detect(transliteration, \"sin|sun|syn\"),\n    auk_uk_ok   = str_detect(transliteration, \"auk|uk|ok\"),\n    at          = str_detect(transliteration, \"at\"),\n#   fathur      = str_detect(transliteration, \"faþur\"),\n    stain_stin  = str_detect(transliteration, \"stain|stin|stӕin\"),\n    lit         = str_detect(transliteration, \"lit\"),\n    across(sin_sun_syn:lit, as.numeric)) ->\n  runes_data\n```\n:::\n\n\nIs this enough information to be able to predict the age of a runic inscription with any accuracy? Let's try fitting a few different models using different approaches.\n\n## Model Fitting\n\n### Test/Training Data Split\n\nFirst we'll split the data into a training and a test set, then create cross-validation folds from training data to help estimate model performance.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_data |>\n  # keep just the features we want to predict from\n  select(\n    object_class, \n    material_class, \n    country, \n    writing_system, \n    inscription_length,\n    abecedarium,\n    spaces,\n    sin_sun_syn:lit,\n    date) |>\n  # discard objects with missing data\n  na.omit() ->\n  runes_data\n\n# split into training (75%) and test (25%) sets, stratified by date\ninitial_split(\n    data = runes_data, \n    prop = 0.75, \n    strata = date) ->\n  split\n\n# store a copy of each set\ntraining(split) -> train\ntesting(split) -> test\n\n# create 10 cross-validation folds\nvfold_cv(train) -> folds\n```\n:::\n\n\nThe `tidymodels` framework provides a unified interface to various model-specific packages, as well as convenient functions for defining, fitting, tuning, and comparing many combinations of data pre-processing recipes and model specifications.\n\n> In parsnip, the model *type* differentiates basic modeling approaches, such as random forests, logistic regression, linear support vector machines, etc.; the *mode* denotes in what kind of modeling context it will be used (most commonly, classification or regression); and the computational *engine* indicates how the model is fit, such as with a specific R package implementation or even methods outside of R like Keras or Stan.\n\n### Pre-Processing Recipe\n\nNext we'll define two pre-processing recipes. In both cases we'll normalize our numeric predictor. Some model types require categorical predictors to be dummy-encoded, while others can exhibit better performance with categorical predictors left as-is. We'll try both ways.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# create a pre-processing recipe\nrecipe(runes_data) |>\n  update_role(date, new_role = \"outcome\") |>\n  update_role(1:(ncol(runes_data) - 1), new_role = \"predictor\") |>\n  # normalize the numeric feature\n  step_normalize(all_numeric_predictors()) |>\n  # dummy encode the categorical features\n  step_dummy(all_nominal_predictors()) ->\n  runes_recipe\n```\n:::\n\n\n### Baseline\n\nNow we can define our models. First let's \"fit\" the null model, which consists of just always guessing the mean date value from the training set. It's straightforward to simply calculate the appropriate RMSE estimate in this case, but for illustrative purposes we'll use cross-validation anyway. It doesn't matter which recipe we use since the null model ignores the predictors anyway.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnull_model() |>\n  set_engine(\"parsnip\") |>\n  set_mode(\"regression\") ->\n  null_spec\n\nworkflow() |>\n  add_model(null_spec) |>\n  add_recipe(runes_recipe) |>\n  fit_resamples(resamples = folds, metrics = metric_set(rmse)) |>\n  collect_metrics() |>\n  pull(mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 311.4979\n```\n:::\n:::\n\n\nThe null model's prediction is, in a certain sense, off by more than three centuries on average. Surely we can do better than that.\n\n### The Bias-Variance Trade-off\n\n### Model Specification\n\nWe'll try six more kinds of model. Each comes with some hyperparameters which control the bias-variance tradeoff, the step size for gradient descent, etc. We can leave `tune()` as a placeholder for these values when creating the model specifications. When we fit the models, we'll try 10 combinations of hyperparameter values for each model type, and keep only the best ones.\n\nA linear model assumes the outcome is a linear function of the predictors and finds the best coefficient to assign to each. Linear models are inflexible, and so tend to suffer from bias (unless the underlying relationship really is approximately linear), but they tend to have lower variance than more flexible model types, since their outputs are not too sensitive to small changes in their inputs. The `penalty` and `mixture` hyperparameters here control how much L1 (LASSO) and/or L2 (ridge) regularization to apply. Regularization penalizes more complex models in order to prevent overfitting.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlinear_reg(\n  engine  = \"glmnet\",\n  penalty = tune(),\n  mixture = tune()) ->\n  linear_spec\n```\n:::\n\n\nA decision tree is essentially a flowchart, with each split corresponding to a rule in the form of an \"if/then\" condition on a predictor. The idea is to find the splits which best separate the outcome. Predictions are produced by taking the average outcome among the training data belonging to the relevant terminal node of the tree. `tree_depth` specifies the maximum depth of the tree; without some maximum, the training data could be completely interpolated (or \"memorized\"), an extreme form of overfitting. `cost_complexity` controls how well a split must separate its subset of the training data in order to be considered, and `min_n` controls how much training data must belong to a node in order to justify any further splitting.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndecision_tree(engine     = \"partykit\",\n              tree_depth = tune(),\n              min_n      = tune()) ->\n  decision_tree_spec\n```\n:::\n\n\nNearest neighbours models predict that the value of the outcome for a test data point will be some kind of weighted average of that point's nearest neighbours in the training data. `neighbors` controls the number of neighbours to consider and the other hyperparameters specify the precise notions of \"weighted average\" and \"nearest\" to use.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnearest_neighbor(engine      = \"kknn\",\n                 neighbors   = tune(),\n                 weight_func = tune(),\n                 dist_power  = tune()) ->\n  nearest_neighbours_spec\n```\n:::\n\n\nBoosted tree ensembles are a very popular machine learning approach involving fitting many small decision trees, each of which is optimized to improve the predictions obtained by combining the preceding trees. This model type inherents the hyperparameters involved in fitting decision trees, plus additional hyperparameters specifying the number of trees to use, the proportion of training data and number of predictors to consider at each step during fitting, as well as how much weight to initially apply to each new tree.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nboost_tree(engine         = \"xgboost\",\n           trees          = 1000,\n           tree_depth     = tune(),\n           min_n          = tune(),\n           loss_reduction = tune(),\n           sample_size    = tune(),\n           mtry           = tune(),\n           learn_rate     = tune()) ->\n  boosted_trees_spec\n```\n:::\n\n\nSome approaches combine multiple other types of models. Cubist involves a tree ensemble with linear models fit on each tree node, a boosting-like procedure, and a final nearest-neighbours-based adjustment.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncubist_rules(engine = \"Cubist\",\n             committees = tune(),\n             neighbors = tune()) ->\n  cubist_spec\n```\n:::\n\n\n### Model Fitting\n\nIn `tidymodels`, a \"workflow\" is an object which bundles together a model specification together with any associated pre-processing recipes, hyperparameter values, and/or evaluation results. `workflow_set` and `workflow_map` allow us to tune all of our model specifications as a batch.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# combine the model specifications in a list\nlist(linear        = linear_spec,\n     tree          = decision_tree_spec,\n     nn            = nearest_neighbours_spec,\n     boosted_trees = boosted_trees_spec,\n     cubist        = cubist_spec) ->\n  runes_model_specs\n\n# set the prediction mode of each engine to \"regression\"\nrunes_model_specs |>\n  map(~set_mode(., \"regression\")) ->\n  runes_model_specs\n\n# combine pre-processing recipe and model specifications into a workflow set\nworkflow_set(preproc = list(recipe = runes_recipe),\n             models = runes_model_specs) ->\n  runes_workflow_set\n\nrunes_workflow_set |>\n  # for each model specification, try ten combinations of tuning parameters\n  # and estimate rmse using cross-validation\n  workflow_map(\"tune_grid\",\n               resamples = folds,\n               grid = 10,\n               metrics = metric_set(rmse)) ->\n  # update the workflow set with the results\n  runes_workflow_set\n```\n:::\n\n\n\n\n\n\n### Performance Comparison\n\nNow our workflow set contains ten fit models per model type for each of ten hyperparameter combinations. We can extract the best version of each model type and plot the cross-validated performance estimates.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# plot the rmse estimate from the best iteration of each type of model\nrank_results(runes_workflow_set, select_best = TRUE) |>\n  group_by(model) |>\n  slice_max(mean) |>\n  select(mean, std_err, model) |>\n  rename(rmse_mean = mean, rmse_std_err = std_err) |>\n  ggplot(aes(x = fct_reorder(model, -desc(rmse_mean)), y = rmse_mean)) +\n  geom_errorbar(aes(ymin = rmse_mean - rmse_std_err,\n                    ymax = rmse_mean + rmse_std_err),\n                width = 0.1,\n                size = 1.5,\n                color = \"#595959\") +\n  labs(x = \"Model Type\",\n       y = \"Estimated RMSE\",\n       title = \"Estimated RMSE for Best Model of Each Type\")\n```\n\n::: {.cell-output-display}\n![](machine_learning_about_runes_files/figure-html/model performance plot-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nIt appears that Cubist and boosted trees models work best for these data. Let's finalize a Cubist model by re-fitting the best one on the entire training set, and seeing how well it predicts the age of artifacts in the test set.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrunes_workflow_set |>\n  # get the cubist workflow\n  extract_workflow(\"recipe_cubist\") |>\n  # get the best cubist hyperparameters and apply them to the workflow\n  finalize_workflow(\n    runes_workflow_set |>\n      extract_workflow_set_result(\"recipe_cubist\") |>\n      select_best(metric = \"rmse\")) |>\n  # fit on the entire training set\n  last_fit(split, metrics = metric_set(rmse)) ->\n  final_cubist\n```\n:::\n\n\n### The Performance-Explainability Trade-off\n\nUnfortunately, our finalized Cubist model is useless. Since we're lost in the woods, we can't actually compute a prediction involving a complicated collection of trees of linear models with hundreds or thousands of coefficients and weights in total.\n\nCan we find a simple decision tree with comparable performance by trying more hyperparameter combinations? Let's set `tree_depth` to 3, find good values for the other hyperparameters, then finalize and evaluate the resulting decision tree model.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndecision_tree_spec |>\n  set_args(tree_depth = 3) |>\n  set_mode(\"regression\") ->\n  decision_tree_spec\n\nworkflow() |>\n  add_model(decision_tree_spec) |>\n  add_recipe(runes_recipe) |>\n  # try 100 combinations of cost_complexity and min_n\n  tune_grid(resamples = folds, metrics = metric_set(rmse), grid = 100) |>\n  # keep the best ones\n  select_best(metric = \"rmse\") |>\n  # plug them back into the model specification\n  finalize_workflow(\n    workflow() |> \n      add_model(decision_tree_spec) |>\n      add_recipe(runes_recipe),\n    parameters = _) |>\n  # fit on the entire training set\n  last_fit(split, metrics = metric_set(rmse)) ->\n  small_tree\n```\n:::\n\n\n\n\n\n\nNow we have two finalized models: a Cubist model and a small decision tree. The most obvious way to compare them would be to inspect their performance, but we can also use the `vip` package to extract the number of features used by each model, giving us a way to compare their relative complexity as well.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata.frame(\n  model    = c(\"Cubist\", \"Small Decision Tree\"),\n  rmse     = c(final_cubist |> collect_metrics() |> pull(.estimate), \n               small_tree   |> collect_metrics() |> pull(.estimate)),\n  features = c(final_cubist |> extract_fit_engine() |> vi() |> filter(Importance > 0) |> nrow(),\n               small_tree   |> extract_fit_engine() |> vi() |> filter(Importance > 0) |> nrow())) |>\n  kbl() |>\n  scroll_box(width = \"51.75%\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div style=\"border: 1px solid #ddd; padding: 5px; overflow-x: scroll; width:51.75%; \"><table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> model </th>\n   <th style=\"text-align:right;\"> rmse </th>\n   <th style=\"text-align:right;\"> features </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Cubist </td>\n   <td style=\"text-align:right;\"> 109.7088 </td>\n   <td style=\"text-align:right;\"> 38 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Small Decision Tree </td>\n   <td style=\"text-align:right;\"> 131.1698 </td>\n   <td style=\"text-align:right;\"> 7 </td>\n  </tr>\n</tbody>\n</table></div>\n\n`````\n:::\n:::\n\n\nThe small decision tree's predictions are about 16% worse than the best Cubist model we could find. On the other hand, it's *much* simpler. While the Cubist model uses essentially all of the information we provided to it, since we constrained our decision tree to three levels, it can use only a maximum of seven features.[^12] Although the more complicated Cubist performs well, it's difficult to explain exactly why, or what the role of each feature is in generating predictions. This illustrates the performance-explainability trade-off.\n\n[^12]: None of which are among the ones we engineered, as it happens.\n\nOur small tree model is simple enough to write on an index card and keep with us when venturing out into the forests of rural Scandinavia. Here it is:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsmall_tree |>\n  extract_fit_engine() |>\n  as.simpleparty() |>\n  plot(\n    ip_args = list(pval = FALSE, id = FALSE),\n    tp_args = list(\n      id = FALSE, \n      FUN = function(node){round(node$prediction[1])}))\n```\n\n::: {.cell-output-display}\n![](machine_learning_about_runes_files/figure-html/tree graphic-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Conclusion\n\nIf you can foresee yourself desperately needing to know the approximate age of a runic inscription, I recommend you write down the decision tree above and keep it in your pocket. That, or always bring a licensed and qualified runologist[^13] with you.\n\n[^13]: The real job title of perhaps an entire dozen people!\n\n## References\n\n### Runes\n\n-   [*Runes and their Origin: Denmark and Elsewhere* (Moltke, 1985)](https://books.google.ca/books/about/Runes_and_Their_Origin.html?id=cjdcAAAAMAAJ)\n-   [*Runes (Findell, 2014)*](https://books.google.ca/books?id=okLarQEACAAJ)\n-   [*Futhark Journal*](http://futhark-journal.com/issues/)\n\n### Statistical Inference and Machine Learning\n\n-   [*Elements of Statistical Learning* (Friedman, et al., 2001)](https://hastie.su.domains/ElemStatLearn/)\n\n### Data Science in R\n\n-   [*Tidy Data* (Wickham, 2014)](https://www.jstatsoft.org/article/view/v059i10)\n-   [*R for Data Science* (Grolemund & Wickham, 2016)](https://r4ds.had.co.nz/)\n-   [*Tidy Modeling with R (Kuhn & Silge, forthcoming)*](https://www.tmwr.org/)\n",
    "supporting": [
      "machine_learning_about_runes_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}